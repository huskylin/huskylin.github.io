{"meta":{"title":"工程師都是中二病","subtitle":"","description":"","author":"huskylin","url":"https://huskylin.github.io","root":"/"},"pages":[{"title":"標籤","date":"2020-06-28T10:07:31.270Z","updated":"2020-06-28T10:07:31.270Z","comments":false,"path":"tags/index.html","permalink":"https://huskylin.github.io/tags/index.html","excerpt":"","text":""},{"title":"404 Not Found","date":"2020-06-28T10:07:53.375Z","updated":"2020-06-28T10:07:53.375Z","comments":false,"path":"/404.html","permalink":"https://huskylin.github.io/404.html","excerpt":"","text":""},{"title":"關於","date":"2020-06-28T10:21:07.494Z","updated":"2020-06-28T10:21:07.494Z","comments":false,"path":"about/index.html","permalink":"https://huskylin.github.io/about/index.html","excerpt":"","text":"技術目前是雜端工程師目前主要技術是JavaScript主要使用Angular框架次要技術則是Python喜歡用技術創造各種東西自己的能力，總是跟不上一堆想玩的東西除了前後端以外，也對APP、資安有興趣 個人成長非常喜歡觀察與思考的東西偶爾看看心理學、哲學批判時事之類的 興趣非常喜歡音樂與唱歌Pop, Jazz, Funk也喜歡健身與烹飪"},{"title":"分類","date":"2020-06-28T10:07:39.017Z","updated":"2020-06-28T10:07:39.017Z","comments":false,"path":"categories/index.html","permalink":"https://huskylin.github.io/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-06-28T07:34:49.290Z","updated":"2020-06-28T07:34:49.290Z","comments":false,"path":"repository/index.html","permalink":"https://huskylin.github.io/repository/index.html","excerpt":"","text":""},{"title":"书单","date":"2020-06-28T07:34:49.277Z","updated":"2020-06-28T07:34:49.277Z","comments":false,"path":"books/index.html","permalink":"https://huskylin.github.io/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-06-28T07:34:49.285Z","updated":"2020-06-28T07:34:49.285Z","comments":true,"path":"links/index.html","permalink":"https://huskylin.github.io/links/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis 做資料快取的基本使用 (搭配Node.js)","slug":"Redis-做資料快取的基本使用-搭配Node-js","date":"2020-07-10T10:11:48.000Z","updated":"2020-10-20T16:40:46.107Z","comments":true,"path":"2020/07/10/Redis-做資料快取的基本使用-搭配Node-js/","link":"","permalink":"https://huskylin.github.io/2020/07/10/Redis-%E5%81%9A%E8%B3%87%E6%96%99%E5%BF%AB%E5%8F%96%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8-%E6%90%AD%E9%85%8DNode-js/","excerpt":"","text":"Redis 做資料快取的基本使用 (搭配Node.js)背景有些需要耗費大量運算的結果如果能夠在伺服器端做快取可以對效能提升很有幫助先看這次的結果左邊為原始情況，右邊為 Redis 快取後(極端案例? T__T 安裝已經有安裝或是只是想看介紹的可以跳過這部分喔~ Redis Server建議採用官網這種下載壓縮檔再安裝的方式不然直接用 apt-get 常常預設的不是最新版本https://redis.io/download#installation $ wget http://download.redis.io/releases/redis-6.0.5.tar.gz $ tar xzf redis-6.0.5.tar.gz $ cd redis-6.0.5 $ make 在背景啟動 redis-server $ src/redis-server --daemonize yes 並且測試一下功能運作正常 $ redis&gt; set foo bar $ OK $ redis&gt; get foo $ &quot;bar&quot; Redis Client我自己是使用 Node.js所以先安裝 node-redis 套件https://github.com/NodeRedis/node-redis npm install redis Github 上的範例也很簡潔清楚 &lt;!-- 引入模組 --&gt; const redis = require(&quot;redis&quot;); const client = redis.createClient(); &lt;!-- 連接 redis server --&gt; client.on(&quot;error&quot;, function(error) { console.error(error); }); &lt;!-- 設置與取得 key / value --&gt; client.set(&quot;key&quot;, &quot;value&quot;, redis.print); client.get(&quot;key&quot;, redis.print); 實際使用使用快取的邏輯 查詢資料時，查看是否存在於快取之中 是，則從快取中取得資料 直接回傳給前端 否，則從資料庫中查詢 回傳給前端 並且寫入快取之中 更新資料時，查看是否存在於快取之中 是，則一併更新快取資料 否，則寫入快取中轉換為程式碼 // 取得圖表資料 router.get(&#39;/someData&#39;, (req, res) =&gt; { // 取得請求參數並傳換成 key const parm1 = req.query.parm1 const parm2 = req.query.parm2 const parm3 = req.query.parm3 const key = (`someData:${parm1}/${parm2}/${parm3}`).trim() const expireDay = 60 * 60 * 24; // 檢查資料是否能夠從快取中取得 redisClient.get(key, (err, rawdata) =&gt; { // 可以做錯誤處理 if (err) { console.log(err) } // 如果快取中沒有這筆資料，會回傳 null if (!!rawdata) { // redis 無法儲存 Javascript 的 Object // 這邊是直接存成 string // 所以需要轉換 const data = JSON.parse(rawdata); return res.json(data); } // 這邊是呼叫你撈資料庫的 function yourSQL.queryData(parm1, parm2, parm3) .then(results =&gt; { // 寫入快取，並且設置有效期限為一天 redisClient.set(key, JSON.stringify(results), &#39;EX&#39;, expireDay, err =&gt; { if (err) { console.log(err) } }); // 回傳資料 res.json(results); }) .catch(err =&gt; { // 資料庫的查詢的錯誤處理 console.log(&quot;not connected due to error: &quot; + err); res.status(500).send(&#39;Can not connect to DB&#39;); }); }); }); 值得注意的地方key 的取名因為 key 的長度會影響到 Redis 查詢的效能所以設計好的 key 是需要的關乎取名的東西要複雜都可以很複雜但我覺得最大原則就是內部溝通好、好管理就好可以參考 SatckOverflow 上有人講到常見的命名方式redis-key-naming-conventions We use a colon (:) as namespace separator and a hash (#) for id-parts of keys, e.g.:logistics:building#23 value 的資料型態Redis 目前有五種資料型態: string hash list set zset (sorted set) 我這邊原本是想直接把資料庫撈出來的結果 (Object型態) 存入但是因為 Redis 並沒有這種資料型態所以就直接粗暴的轉成字串存入與取出時透過JSON.stringify, JSON.parse 來處理應該有更好的做法啦 有效期限的設置 如果不是需要常駐的資料 盡量都要設置有效期限 (需要常駐的資料也應該要記得存於實體資料庫中) 設置合理的有效期限 太長，占用記憶體空間 太短，容易重覆讀寫浪費效能 在範例的 Node.js 中 語法為在 set 方法裡傳入參數 &#39;EX&#39;, expire redisClient.set(key, value, &#39;EX&#39;, expire, err =&gt; { ... }); 超過記憶體上限後的處理、淘汰機制 noeviction: 即使記憶體上達到上限，也不置換 key-value 也就是記憶體滿了之後，只能讀取資料，不能寫入 若再新增資料會 return error 這是預設值，我認為不適用於多數場合，所應該要去設定成下列其他的 allkeys-lru: 優先刪除掉最近最少使用的key，用以保存新數據 LRU = least recently used適用多數場合 volatile-lru: 只從有設置有效期限 (expire) 的資料中 選擇最近最少使用的 key-value 進行刪除 與 allkeys-lru 的差別在於一個從全部的 key 中來選擇刪除一個是只會從有有效期限的 key 來選擇刪除 allkeys-random: 從全部的 key 中 隨機選擇一些進行刪除 volatile-random: 只從有設置有效期限 (expire) key 中 隨機選擇一些 key 進行刪除 volatile-ttl: 只從有設置有效期限 (expire) key 中 選出剩餘存活時間 (TTL) 最短的 key 進行刪除 TTL = Time To Live 其他參考資料 [Node.js] 使用 Redis 內存來存取本地資料 Redis的过期策略及淘汰策略 Redis删除策略和逐出策略","categories":[],"tags":[{"name":"部屬","slug":"部屬","permalink":"https://huskylin.github.io/tags/%E9%83%A8%E5%B1%AC/"},{"name":"Node.js","slug":"Node-js","permalink":"https://huskylin.github.io/tags/Node-js/"}]},{"title":"MySQL 在每個群組中取 N 筆資料 ( Get 1...N Results From Each Group )","slug":"MySQL-在每個群組中取-N-筆資料-Get-1-N-Results-From-Each-Group","date":"2020-06-28T07:27:47.000Z","updated":"2020-06-28T08:59:40.269Z","comments":true,"path":"2020/06/28/MySQL-在每個群組中取-N-筆資料-Get-1-N-Results-From-Each-Group/","link":"","permalink":"https://huskylin.github.io/2020/06/28/MySQL-%E5%9C%A8%E6%AF%8F%E5%80%8B%E7%BE%A4%E7%B5%84%E4%B8%AD%E5%8F%96-N-%E7%AD%86%E8%B3%87%E6%96%99-Get-1-N-Results-From-Each-Group/","excerpt":"","text":"MySQL 在每個群組中取 N 筆資料 ( Get 1…N Results From Each Group )背景如果只想撈取 GROUP BY 後，每一個 GROUP 裡面的前 1…n 筆資料例如: Person Height Weight UpdateTime Andy 150 52 2018-06-01 Andy 155 55 2019-08-01 Andy 160 58 2020-09-01 Bob 162 57 2018-06-01 Bob 164 62 2019-08-01 Bob 168 65 2020-09-01 這是一張記錄身高體重的表而決定每筆資料是唯一的 PK 就是Name + UpdateTime 問題假設想要取得每個人最新的體態資料那麼直覺就會想到先把他們 GROUP BY 後再來用 ORDER BY再來用 LIMIT再來用….. 到底要用啥最後腦袋一片渾沌地組出一坨勉強通過語法檢查的式子 SELECT Person, Height, Weight, UpdateTime FROM BodyInfoTable GROUP BY Person, UpdateTime ORDER BY UpdateTime DESC LIMIT 1 然後就可以開開心心地看見…各種錯誤與不是你想要的結果 :) 解法一，使用 Variables那麼再來就是這次的主題針對每一個 GROUP 取幾筆資料查詢了 StackOverflow 上的問答後的解法Using LIMIT within GROUP BY to get N results per dynamic groupmysql limit inside group套用在範例的情境中就會長這樣 SELECT Person, Height, Weight, UpdateTime FROM (SELECT x.*, CASE WHEN @prev = Person THEN @i:=@i + 1 ELSE @i:=1 END i, @prev:=Person FROM BodyInfoTable x, (SELECT @prev:=NULL, @i:=0) vars ORDER BY Person, UpdateTime ) a WHERE i &lt;= 1; 最關鍵的部分就是它使用了Variables搭配case-when來完成當 Person 欄位重覆的時候 i 就會 +1調整 ORDER BY 與 i &lt;= 多少就可以決定想要按照什麼條件來取得前 n 筆資料了 Variables 變數: @prev:=Person You can store a value in a user-defined variable in one statement and refer to it later in another statement. This enables you to pass values from one statement to another. 出現另一個問題原本想說大功告成，這長得這麼醜複雜把它儲存成 View 吧登愣~ 直接噴出一個大大的錯誤Error 1351: View&#39;s SELECT contains a variable or parameter SQL Statement:...直接拿錯誤餵狗後才知道View 裡面是不能使用 Variables 的!!如果堅持要用，就必須用很 tricky 的寫法看到這邊…我只能說「我OK，你先用」馬上跳槽用別的寫法 解法二，使用 ROW_NUMBER()原來這種類型的操作是因為在MySQL 8以前才需要這麼克難、展現手做職人精神MySQL 8以後就直接用超棒棒函數就好啦In MySQL 8 or later just use the RANK, DENSE_RANK or ROW_NUMBER functions:套用在範例的SQL就會長這樣 SELECT Person, Height, Weight, UpdateTime FROM ( SELECT *, ROW_NUMBER() OVER (partition by Person ORDER BY Person, UpdateTime) AS vars FROM TainanParking.GridStatic ) as a WHERE num &lt;= 1 撈出來應該就會像是 Person Height Weight UpdateTime Andy 160 58 2020-09-01 Bob 168 65 2020-09-01 這種寫法真的是好多了而且這個需求應該很常用到，趕緊筆記起來終於打完了~ 下課啦~","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://huskylin.github.io/tags/MySQL/"}]},{"title":"Node.js + PM2 設置環境變數，更彈性地開發與部屬","slug":"Node-js-PM2-設置環境變數，更彈性地開發與部屬","date":"2020-06-18T10:10:00.000Z","updated":"2020-07-18T10:11:22.883Z","comments":true,"path":"2020/06/18/Node-js-PM2-設置環境變數，更彈性地開發與部屬/","link":"","permalink":"https://huskylin.github.io/2020/06/18/Node-js-PM2-%E8%A8%AD%E7%BD%AE%E7%92%B0%E5%A2%83%E8%AE%8A%E6%95%B8%EF%BC%8C%E6%9B%B4%E5%BD%88%E6%80%A7%E5%9C%B0%E9%96%8B%E7%99%BC%E8%88%87%E9%83%A8%E5%B1%AC/","excerpt":"","text":"Node.js + PM2 設置環境變數，更彈性地開發與部屬背景在使用 node.js 時一定會遇到開發(dev)與生產(production)，甚至更多階段的不同環境可能每一種環境都有不同的設定檔案例如:開發階段要連線到本機的資料庫生產階段要連線到另一台伺服器的資料庫這時候就需要更彈性的來做設定 在 Node.js 設定 config可以針對不同的階段環境來設定各種連線參數例如: const env = process.env.NODE_ENV; // &#39;dev&#39; or &#39;prod&#39; const configs = {} configs.dev = { db: { host: &#39;YourHost1&#39;, port: 3306, user: &quot;YourUser&quot;, password: &#39;yourPassword1&#39;, database: &#39;YourDB1&#39; } }; configs.prod = { db: { host: &#39;YourHost2&#39;, port: 3306, user: &quot;YourUser2&quot;, password: &#39;yourPassword2&#39;, database: &#39;YourDB2&#39; } } module.exports = configs[env]; 如此一來 Node.js 就會根據環境變數來 exports 不同的設定 使用 PM2 來運行 Node.js 時PM2 是一個 node 的程序管理器主要功能有自動重啟服務, 叢集功能更有效的利用多核CPU等等網路上介紹非常多，可以參考這些連結來看介紹與用法 pm2 - 用法大全 使用 pm2 啟動 Node.js cluster 以提升效能 我主要想分享的是，當我們使用 PM2 時希望在叢集模式(cluster)下運行Node服務，又要設定環境變數時的作法一開始直覺的想法是直接都打在參數 how to “npm start” with pm2 cluster mode Passing environment variables to node.js using pm2 後來發現比較好的做法，是設置一個PM2的參數設定檔(後來才發現其實官方的文件就寫得很清楚了) 使用 Ecosystem FilePM2官方文件 先產生一個ecosystem.config.js 設置範例 module.exports = { apps : [{ name: &quot;app&quot;, script: &quot;./app.js&quot;, env: { NODE_ENV: &quot;development&quot;, }, env_production: { NODE_ENV: &quot;production&quot;, } }] } 運行指令 pm2 start ecosystem.config.js --env production 這裡值得留意的是在上面的例子中，--env這個參數後面接是production而不是env_production我原本想說應該是要輸入設定檔的 Object key結果直接失敗，我還不夠難嗎?差點躺在床上蓋著面被抱著自己哭出來 後來又發現其實在更下面的官方文件又有說明了 Example: # Inject what is declared in env_production pm2 start process.json --env production # Inject what is declared in env_staging pm2 restart process.json --env staging ( 害我不能怪官方沒寫清楚了 )( 改怪他怎麼分那麼開好了 QQ ) 廢話時間改造完自己的設置是不是覺得自己的Node.js Server變得更進化啦進化為 Dev &amp; Production 皆可適應的雙棲動物獻唱一首蔡健雅的雙棲動物 很想哭~ 哭完無助~ 打完收工!","categories":[],"tags":[{"name":"部屬","slug":"部屬","permalink":"https://huskylin.github.io/tags/%E9%83%A8%E5%B1%AC/"},{"name":"Node.js","slug":"Node-js","permalink":"https://huskylin.github.io/tags/Node-js/"}]},{"title":"在Node.JS透過ODBC連接impala完整教學(下)","slug":"在Node-JS透過ODBC連接Impala完整教學-下","date":"2020-06-17T10:00:22.000Z","updated":"2020-06-28T09:14:55.305Z","comments":true,"path":"2020/06/17/在Node-JS透過ODBC連接Impala完整教學-下/","link":"","permalink":"https://huskylin.github.io/2020/06/17/%E5%9C%A8Node-JS%E9%80%8F%E9%81%8EODBC%E9%80%A3%E6%8E%A5Impala%E5%AE%8C%E6%95%B4%E6%95%99%E5%AD%B8-%E4%B8%8B/","excerpt":"","text":"在Node.JS透過ODBC連接Impala完整教學(下)步驟二，在 Node.js 上連接到 Ubuntu 上的 ODBC上一篇完成了在 Ubuntu 上安裝 ODBC Driver的部分接下來就是透過 Node.js來連接啦 1. 安裝套件看了一下 Node.js 連接 ODBC的 相關套件這套是到近期都還有有維持更新的，因此採用node-odbc npm install odbc 2. 設定連接官方範例 const odbc = require(&#39;odbc&#39;); async function connectToDatabase() { const connection1 = await odbc.connect(&#39;DSN=MYDSN&#39;); // connection1 is now an open Connection // or using a configuration object const connectionConfig = { connectionString: &#39;DSN=MYDSN&#39;, connectionTimeout: 10, loginTimeout: 10, } const connection2 = await odbc.connect(connectionConfig); // connection2 is now an open Connection } connectToDatabase(); 這邊比較要注意的是connectionString: &#39;DSN=MYDSN&#39;這個DSN就是Data Source Name如果是按照上一篇的範例，我們是取名為impalaodbc所以會長這樣 const connectionConfig = { connectionString: &#39;DSN=impalaodbc&#39;, connectionTimeout: 10, loginTimeout: 10, } 3. 執行 Query執行 Query、Pool 可以在官方文件上查詢 API 與範例這個套件的官方文件 API 寫得蠻清楚的主要可以在上面看但是值得注意的是Impala 的欄位名稱是不分大小寫的Impala 的欄位名稱是不分大小寫的Impala 的欄位名稱是不分大小寫的 Impala identifiers are always case-insensitive. That is, tables named t1 and T1 always refer to the same table, regardless of quote characters. Internally, Impala always folds all specified table and column names to lowercase. This is why the column headers in query output are always displayed in lowercase.官方文件說明 像我是從MySQL轉移過來的就會遇到問題所以我寫了一個取代欄位名稱的 Function第一個參數是從Impala撈回來的資料第二個參數則是你希望取代的欄位名稱例如: [&#39;Id&#39;, &#39;InfoDate&#39;, &#39;ColName&#39;, &#39;Something&#39;...]直接取代每一個物件的key function toCaseSensitiveKeys(result, newKeys) { // make keys array to keys object const replacements = {}; if (newKeys !== undefined) { newKeys.forEach(key =&gt; { replacements[key.toLowerCase()] = key; }) } // pair keys by replacements object const data = result.map(row =&gt; { const replacedItems = Object.keys(row).map(key =&gt; { const newKey = replacements[key] || key; return { [newKey]: row[key] }; }) const newResult = replacedItems.reduce((a, b) =&gt; Object.assign({}, a, b)); return newResult; }); return data; } 最後的 Query Function const impalaQuery = (sql, values, newKeys) =&gt; { return new Promise((resolve, reject) =&gt; { // Create Connection Pool const connectionConfig = { connectionString: &#39;DSN=impalaodbc&#39;, connectionTimeout: 10, loginTimeout: 10, } odbc.connect(connectionConfig, (conError, connection) =&gt; { if (conError) { reject(conError); } connection.query(sql, values, (err, rows) =&gt; { if (err) { // If execute SQL faild, print SQL connection.createStatement((error1, statement) =&gt; { if (error1) { console.log(error1, statement); return; } // handle statement.prepare(sql, (error2) =&gt; { if (error2) { console.log(error2, statement); return; } // handle statement.bind(values, (error3) =&gt; { if (error3) { console.log(error3, statement); return; } // handle }); }); }); reject(err); } else { const idx = rows.indexOf(&#39;statement&#39;) const values = rows.slice(0, idx).map((e, i) =&gt; { return e }) const data = toCaseSensitiveKeys(values, newKeys); // print SQL console.log(rows[&#39;statement&#39;]); resolve(data); } }); }); }); }; 主要是加入了 錯誤時透過階段來偵錯 印出執行的SQL 轉換大小寫 在其他地方就可以這樣使用 const sql = &#39;yourSQL&#39;; const values = [SomeParms...]; const keys = [SomeColNames...]; impalaQuery(sql, values, keys) .then(results =&gt; { res.status(200).json(results); }) .catch(err =&gt; { console.log(err); res.status(500).send(&#39;DB Error&#39;); }); 這次的在Node.JS透過ODBC連接Impala就大功告成啦!其實蠻費工的，寫這篇文時也回顧了不少苦難希望可以幫助到有同樣需求的人~","categories":[],"tags":[{"name":"部屬","slug":"部屬","permalink":"https://huskylin.github.io/tags/%E9%83%A8%E5%B1%AC/"},{"name":"Node.js","slug":"Node-js","permalink":"https://huskylin.github.io/tags/Node-js/"},{"name":"impala","slug":"impala","permalink":"https://huskylin.github.io/tags/impala/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://huskylin.github.io/tags/ubuntu/"},{"name":"hadoop","slug":"hadoop","permalink":"https://huskylin.github.io/tags/hadoop/"}]},{"title":"在Node.JS透過ODBC連接impala完整教學(上)","slug":"在Node-JS透過ODBC連接Impala完整教學-上","date":"2020-06-15T10:00:22.000Z","updated":"2020-06-28T09:13:14.306Z","comments":true,"path":"2020/06/15/在Node-JS透過ODBC連接Impala完整教學-上/","link":"","permalink":"https://huskylin.github.io/2020/06/15/%E5%9C%A8Node-JS%E9%80%8F%E9%81%8EODBC%E9%80%A3%E6%8E%A5Impala%E5%AE%8C%E6%95%B4%E6%95%99%E5%AD%B8-%E4%B8%8A/","excerpt":"","text":"在Node.JS透過ODBC連接Impala完整教學(上)背景原本專案的後端，在開發階段時採用Node.js連接MySQL結果後來到部屬階段時要改連接到impala原本以為是小事一樁，後來採坑連連於是產生了本篇筆記 初始想法 node-impala 套件一開始看到 npm 裡面已經有人做好套件了連接範例看起來也蠻簡潔的就直接採用 node-impala測試後的確也蠻快就能夠連上並且撈取資料但是!!過很久之後才發現他的query一次最多回傳1024筆結果!他的query一次最多回傳1024筆結果!他的query一次最多回傳1024筆結果! 看了issue後才發現是因為底層使用Beeswax來連接，這是Beeswax的限制無法改變 Beeswax limits the query result. It is not possible to increase the size by setting fetch_size here. Let’s use the HiveServer2 #4. 🙈 原討論串 煎熬了一陣子後決定直接放棄另尋他路 解法 ODBC後來找到的方法是在系統環境下先裝好 ODBC 來連接 Impala後端 Node.js 再去連 ODBC我們的作業系統環境是使用Ubuntu 18.04所以接下來就是有兩個步驟要執行 在 Ubuntu 上安裝 ODBC Driver 在 Node.js 上連接到 Ubuntu 上的 ODBC 步驟一，在 Ubuntu 上安裝 ODBC Driver1. 下載安裝包cloudera下載連結Cloudera ODBC Driver for Impala 官方文件說明 2. 設定環境變數export LD_LIBRARY_PATH=/usr/local/lib:/opt/cloudera/impalaodbc/lib/64 export CLOUDERAIMPALAINI=/opt/cloudera/impalaodbc/lib/64/cloudera.impalaodbc.ini export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libodbcinst.so export ODBCINI=/etc/odbc.ini export ODBCSYSINI=/etc 3. 設定 ODBC driver 的參數檔大致上長這樣比較需要注意的地方是 [impalaodbc] 這是你自己要取的 Data Source Name PORT要注意一下是21050還是21000 `Drive‵路徑 帳號密碼、DB位置等等其他都是預設值而已，自行參考變化即可 [impalaodbc] # Description: DSN Description. This key is not necessary and is only to give a description of the data # source. Description=Cloudera ODBC Driver for Impala (64-bit) DSN # Driver: The location where the ODBC driver is installed to. Driver=/opt/cloudera/impalaodbc/lib/64/libclouderaimpalaodbc64.so # The DriverUnicodeEncoding setting is only used for SimbaDM When set to 1, SimbaDM runs in UTF-16 mode. When #set to 2, SimbaDM runs in UTF-8 mode. DriverUnicodeEncoding=2 # Values for HOST, PORT, KrbFQDN, and KrbServiceName should be set here. They can also be specified on the # connection string. HOST=Impala Server的IP位置 PORT=21050 Database=DB名稱 # The authentication mechanism. 0 - no authentication. 1 - Kerberos authentication 2 - Username # authentication. 3 - Username/password authentication. 4 - Username/password authentication with SSL. AuthMech=0 # Kerberos related settings. KrbFQDN= KrbRealm= KrbServiceName= # Username/password authentication with SSL settings. UID=DB帳號 PWD=DB密碼 CAIssuedCertNamesMismatch=1 TrustedCerts=/opt/cloudera/impalaodbc/lib/64/cacerts.pem # Specify the proxy user ID to use. DelegationUID= # General settings TSaslTransportBufSize=1000 RowsFetchedPerBlock=1000 SocketTimeout=0 4. 安裝 unixODBCsudo apt-get install unixODBC unixODBC-dev 5. 測試 查看你的ODBC設定 odbcinst -q -s 如果成功的話應該會顯示你的 Data Source Name 測試連線 isql -v impalaodbc 如果成功的話應該會顯示你的連線後介面 到這部分完成了在 Ubuntu 上安裝 ODBC Driver\\ 恭喜恭喜 / \\ 灑花灑花/喘口氣，下一篇再來講 步驟二 Node.js 的部分~ 參考連結 Installing Impala ODBC Driver in Ubuntu 64 bit Impala ODBC 安装笔记 ubuntu14.04配置impala的odbc连接","categories":[],"tags":[{"name":"部屬","slug":"部屬","permalink":"https://huskylin.github.io/tags/%E9%83%A8%E5%B1%AC/"},{"name":"Node.js","slug":"Node-js","permalink":"https://huskylin.github.io/tags/Node-js/"},{"name":"impala","slug":"impala","permalink":"https://huskylin.github.io/tags/impala/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://huskylin.github.io/tags/ubuntu/"},{"name":"hadoop","slug":"hadoop","permalink":"https://huskylin.github.io/tags/hadoop/"}]},{"title":"Ubuntu Server 18.04 離線狀態下安裝 MySQL","slug":"Ubuntu-Server-18-04-離線狀態下安裝-MySQL","date":"2019-07-16T03:35:15.000Z","updated":"2020-06-16T03:46:11.270Z","comments":true,"path":"2019/07/16/Ubuntu-Server-18-04-離線狀態下安裝-MySQL/","link":"","permalink":"https://huskylin.github.io/2019/07/16/Ubuntu-Server-18-04-%E9%9B%A2%E7%B7%9A%E7%8B%80%E6%85%8B%E4%B8%8B%E5%AE%89%E8%A3%9D-MySQL/","excerpt":"","text":"在 Ubuntu Server 18.04 離線狀態下安裝 MySQL (Install MySQL on Ubuntu While Offline)背景最近一個專案遇到的情況，基於資安政策考量，規定機器不能連外部網路這樣就不能直接使用sudo apt-get install mysql-serve來安裝過程蠻不方便的，記錄一下給遇到同樣處境的人。作法主要參考了這篇文章: ubuntu16.04 安装离线 mysql5.7.17但是MySQL 8.0 版本與以前的版本安裝步驟略有不同，會在以下內容中提到 準備安裝包1. 下載對應的 MySQL 安裝包本文以Ubuntu Linux 18.04 (x86, 64-bit), DEB Bundle為例 2. 準備 USB檢查一下裡面包含這些檔案把mysql-server_8.0.16–2ubuntu18.04_amd64.deb-bundle.tar放置到 USB 隨身碟裝置中 註記: 這邊 USB 要先在 Ubuntu 環境中測試看看能不能用，有些需要重新格式化 掛載 USB 隨身碟1. 先查 USB 隨身碟是被系統辨識成那個裝置fdisk -lsda 很可能是硬碟,往下查容量可以找到隨身碟的編號我們假設為 sdb 2. 建立 USB 隨身碟的掛載點：mkdir /mnt/usb 3. 掛載 USB 隨身碟mount -v -t auto /dev/sdb /mnt/usb -v 顯示資訊-t auto 讓系統自動分辯檔案系統 4. 到 /mnt/usb 可看到 usb 的內容解壓縮後檢視一下檔案 註記: 檔名多一個(1)的部份是我有重新下載過第一次下載時不知道是不是檔案有毀損，出現異常錯誤如果有遇到也可以試試看重新下載 開始安裝1. 下載依賴的安裝包根據參考文章，還需要兩個額外依賴包，可以在這邊下載https://pkgs.org/download/libaio1https://pkgs.org/download/libmecab2 2. 安裝 MySQL sudo dpkg -i mysql-common_8.0.16–2ubuntu18.04_amd64.deb sudo dpkg-preconfigure mysql-community-server_8.0.16–2ubuntu18.04_amd64.deb(這步驟會跳出安裝畫面，並且需要輸入 root 密碼) sudo dpkg -i libmysqlclient21_8.0.16–2ubuntu18.04_amd64.deb sudo dpkg -i libmysqlclient-dev_8.0.16–2ubuntu18.04_amd64.deb 參考文章中這一步是安裝libmysqld-dev_5.7.16–1ubuntu16.04_amd64.deb但是根據官方版本資訊，8.0 版本已經不需要這個檔案了，所以不需要做這個步驟 參考文章中的這步驟是安裝mysql-community-client_8.0.16–2ubuntu18.04_amd64.deb不過如果直接安裝會跳出錯誤，顯示缺少依賴，所以在這 8.0 中需要先安裝mysql-community-client-core_8.0.16–2ubuntu18.04_amd64.deb所以執行sudo dpkg -i mysql-community-client-core_8.0.16–2ubuntu18.04_amd64.deb sudo dpkg -i mysql-community-client_8.0.16–2ubuntu18.04_amd64.deb sudo dpkg -i mysql-client_8.0.16–2ubuntu18.04_amd64.deb sudo dpkg -i mysql-common_8.0.16–2ubuntu18.04_amd64.deb 參考文章中的這步驟是安裝mysql-community-server_8.0.16–2ubuntu18.04_amd64.de不過如果直接安裝會跳出錯誤，顯示缺少依賴，所以在這 8.0 中需要先安裝mysql-community-server-core_8.0.16–2ubuntu18.04_amd64.deb所以執行sudo dpkg -i mysql-community-server-core_8.0.16–2ubuntu18.04_amd64.deb sudo dpkg -i mysql-community-server_8.0.16–2ubuntu18.04_amd64.deb sudo dpkg -i mysql-server_8.0.16–2ubuntu18.04_amd64.deb打完這一大坨指令後，就大功告成啦!最後可以去 MySQL 裡面試一下指令，確認安裝結果mysql -u root -p","categories":[],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://huskylin.github.io/tags/Ubuntu/"},{"name":"部屬","slug":"部屬","permalink":"https://huskylin.github.io/tags/%E9%83%A8%E5%B1%AC/"},{"name":"MySQL","slug":"MySQL","permalink":"https://huskylin.github.io/tags/MySQL/"}]},{"title":"Leaflet讀取GeoJSON檔","slug":"Leaflet讀取GeoJSON檔","date":"2018-10-07T10:00:22.000Z","updated":"2020-06-28T09:19:21.981Z","comments":true,"path":"2018/10/07/Leaflet讀取GeoJSON檔/","link":"","permalink":"https://huskylin.github.io/2018/10/07/Leaflet%E8%AE%80%E5%8F%96GeoJSON%E6%AA%94/","excerpt":"","text":"Leaflet 讀取 GeoJSON 檔透過在地圖上把台灣縣市地區框選起來並且點擊後會有 popup 提示該地區的縣市名稱練習 Leaflet 的一些操作 起步先照著官網教學引入相關文件把初始地圖建出來https://leafletjs.com/examples/quick-start/ // 建立 Leaflet 地圖 var map = L.map(&quot;mapid&quot;); // 設定經緯度座標 map.setView(new L.LatLng(25, 121.74739), 13); // 設定圖資來源 var osmUrl = &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;; var osm = new L.TileLayer(osmUrl, { minZoom: 3, maxZoom: 16 }); map.addLayer(osm); 讀入 GeoJSON 檔根據Web 視覺化(四)：建立 OpenStreetMap 地圖提到 Leaflet 無法直接讀取 GeoJSON 檔案，必須先透過 Ajax 等方式下載下來才行。這邊將使用 jQuery 做例子 $.getJSON(&quot;YOURFILE.json&quot;, function (r) { L.geoJSON(r, { color: &quot;#333&quot; }).addTo(map); }); 這樣就可以讀取 geoJSON 替區塊著色希望讓不同區塊有不同顏色這邊試做一個，把新北市著色 $.getJSON(&quot;taiwan.json&quot;, function (r) { L.geoJSON(r, { // 樣式可透過function操作 style: function (feature) { if (feature.properties.COUNTYID == 65) { console.log(feature.properties.NAME_2014); return { color: &quot;#4f45c0&quot; }; } else { return { color: &quot;#444444&quot; }; } }, onEachFeature: onEachFeature, }).addTo(map); }); 點擊區塊彈出提示這邊希望該縣市區塊後會彈出提示的視窗這邊的 NAME_2014 是該資料中的 properties 有這個 NAME_2014 屬性裡面是該縣市地區的名字 // 綁定每個feature做Popup，可以視資料有什麼properties來決定 function onEachFeature(feature, layer) { if (feature.properties &amp;&amp; feature.properties.NAME_2014) { layer.bindPopup(feature.properties.NAME_2014); } } 另外再加入官網範例中點地圖的其他位置後顯示座標位置 var popup = L.popup(); function onMapClick(e) { popup .setLatLng(e.latlng) .setContent(&quot;You clicked the map at &quot; + e.latlng.toString()) .openOn(map); } map.on(&quot;click&quot;, onMapClick); 其他延伸如果想要自己繪製可以使用geojson.io的服務 資料來源中華民國縣市的 geojson 檔Leaflet 對 GeoJSON 的官方說明老外教學影片","categories":[],"tags":[{"name":"Leaflet","slug":"Leaflet","permalink":"https://huskylin.github.io/tags/Leaflet/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://huskylin.github.io/tags/JavaScript/"}]},{"title":"CSS放大圖片會爆框","slug":"CSS放大圖片會爆框","date":"2018-09-01T10:08:02.000Z","updated":"2020-06-28T09:15:57.653Z","comments":true,"path":"2018/09/01/CSS放大圖片會爆框/","link":"","permalink":"https://huskylin.github.io/2018/09/01/CSS%E6%94%BE%E5%A4%A7%E5%9C%96%E7%89%87%E6%9C%83%E7%88%86%E6%A1%86/","excerpt":"","text":"初步想法想要實作一個滑鼠放上去時會放大圖片簡單的效果使用到的技巧 :hover Selectors(選擇器)用來選擇滑鼠指標經過在上面時的元素 transform: scale()transform 屬性裡，用來縮放元素大小 這兩個加起來就可以做出上述的效果不過被選擇到放大後的圖片會爆出框框這時候就需要加上overflow: hidden當超出邊界範圍時，將多餘的部分隱藏起來不顯示 問題原本以為到這邊就可以成功將效果呈現但是卻發現會因為 padding 的間距讓圖片放大的範圍有了”亂長大的空間” 解決後來在圖片外面多包一個 div並將 overflow: hidden 寫在裡面文字與圖片間的 padding 就不會給圖片亂長大的空間了 .col-grid { max-width: 450px; overflow: hidden; img { max-width: 450px; &amp;:hover { transform: scale(1.1); transition: 0.5s; } } } 結果左邊為目標效果，右邊是有非預期爆框的效果","categories":[],"tags":[{"name":"CSS","slug":"CSS","permalink":"https://huskylin.github.io/tags/CSS/"}]},{"title":"用Python打造FB抽獎機，將回覆留言也列入參抽獎單","slug":"用Python打造FB抽獎機，將回覆留言也列入參抽獎單","date":"2018-05-13T10:11:47.000Z","updated":"2020-06-14T11:23:50.492Z","comments":true,"path":"2018/05/13/用Python打造FB抽獎機，將回覆留言也列入參抽獎單/","link":"","permalink":"https://huskylin.github.io/2018/05/13/%E7%94%A8Python%E6%89%93%E9%80%A0FB%E6%8A%BD%E7%8D%8E%E6%A9%9F%EF%BC%8C%E5%B0%87%E5%9B%9E%E8%A6%86%E7%95%99%E8%A8%80%E4%B9%9F%E5%88%97%E5%85%A5%E5%8F%83%E6%8A%BD%E7%8D%8E%E5%96%AE/","excerpt":"","text":"動機最近在臉書上參加活動需要朋友們按讚我就辦了個抽獎讓大家參與搜尋一下線上工具搜尋結果前幾個似乎都無法免費支援個人頁面的抽獎 影片教學剛好之前看到Pycone 松果城市有相關的教學影片看上去不會太複雜，就照著實作一次了 前就如影片所示 取得 Post 的 ID Facebook Graph API 取得 Token (存取權杖) 拿到資料 不過做到中間發現 這個教學也是做給粉絲團使用的 我希望讓留言中回覆的人也加入名單 所以需要修改一下 取得留言的回覆由於 Facebook 的巢狀留言結構每個留言也都有各自獨立的 ID要一一抓取有點麻煩這邊直接在語法的地方使用 filter=stream 讓它變成資料流，就會全部展開來了 另外如果留言數太多的話還要加上 limit否則有些會顯示不出來想要全部顯，就給一個超過總留言數的數量即可 limit=1000 最後的語法為 &lt;Your_Post_ID&gt;/comments?filter=stream&amp;limit=1000 最後取得資料後再利用 SET 去除重複名單，亂數排序後印出就可以完成了 完整的程式碼短短幾行就可以完成了","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://huskylin.github.io/tags/Python/"}]}],"categories":[],"tags":[{"name":"部屬","slug":"部屬","permalink":"https://huskylin.github.io/tags/%E9%83%A8%E5%B1%AC/"},{"name":"Node.js","slug":"Node-js","permalink":"https://huskylin.github.io/tags/Node-js/"},{"name":"MySQL","slug":"MySQL","permalink":"https://huskylin.github.io/tags/MySQL/"},{"name":"impala","slug":"impala","permalink":"https://huskylin.github.io/tags/impala/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://huskylin.github.io/tags/ubuntu/"},{"name":"hadoop","slug":"hadoop","permalink":"https://huskylin.github.io/tags/hadoop/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://huskylin.github.io/tags/Ubuntu/"},{"name":"Leaflet","slug":"Leaflet","permalink":"https://huskylin.github.io/tags/Leaflet/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://huskylin.github.io/tags/JavaScript/"},{"name":"CSS","slug":"CSS","permalink":"https://huskylin.github.io/tags/CSS/"},{"name":"Python","slug":"Python","permalink":"https://huskylin.github.io/tags/Python/"}]}